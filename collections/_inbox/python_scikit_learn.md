---
date    : 2021-11-13
title   : ã€ğŸ Pythonã€‘ scikit-learnã§åˆ†é¡ã¨å›å¸°
excerpt : ã‚¢ãƒ¤ãƒ¡ã®åˆ†é¡äºˆæ¸¬ã€‚ä½å®…ä¾¡æ ¼ã®å›å¸°äºˆæ¸¬ã€‚
tags    : ["Python3", "scikit-lean", "Classification", "Regresion"]
---

## || scikit-learn

### |

[scikit-learn](https://scikit-learn.org/stable/user_guide.html)

+ ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
+ (2007å¹´) Google Summer of Code projectã¨ã—ã¦David Cournapeauæ°ã«ã‚ˆã£ã¦é–‹ç™º
+ `NumPy`ã€`SciPy`ã€`matplotlib`ã¨ã„ã£ãŸPythonã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¸Šã§å‹•ä½œ
+ æ‰‹è»½ã«æ©Ÿæ¢°å­¦ç¿’ã® å‰å‡¦ç†ã€ ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã€ è©•ä¾¡æŒ‡æ¨™ç®—å‡º
+ ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒè±Šå¯Œ

### | ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒãƒ¼ãƒˆã‚·ãƒ¼ãƒˆï¼ˆå…¬å¼ï¼‰
![](https://www.codexa.net/wp-content/uploads/2020/09/ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ-2020-09-29-11.20.30.png)


## || ã‚„ã£ã¦ã¿ã‚ˆã†
### | åˆ†é¡äºˆæ¸¬
```Python
import sklearn
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklean.metrics import confusion_matrix
# ALGORITHM
from sklearn import svm
from sklearn.neighbors import KNeighborsClassifier


# DATASET
iris = load_iris()
iris_features = pd.DataFrame(data = iris.data, columns = iris.feature_names)
iris_label = pd.Series(iris.target)

# EDA
# iris_features.head(10)
# iris_features.describe()
# iris_features.isnull().sum()
# iris_label.head()
# iris_label.value_counts()


features_train, features_test, label_train, label_test = train_test_split(iris_features, iris_label, test_size=0.5, random_state=0)
# print('features_train: {}'.format(features_train.shape))
# print('features_test: {}'.format(features_test.shape))
# print('label_train: {}'.format(label_train.shape))
# print('label_test: {}'.format(label_test.shape))

# MODEL
svc = svm.LinearSVC(random_state=0, max_iter=3000)
svc.fit(features_train, label_train)
pred_svc = svc.predict(features_test)
# print(pred_svc)

'''
SVCã®äºˆæ¸¬ãŒä¸Šæ‰‹ãæŒ¯ã‚‹ã‚ãªã„æ™‚ã®ãƒ¢ãƒ‡ãƒ«ç¾¤
'''
kn = KNeighborsClassifier(n_neighbors=5)
kn.fit(features_train, label_train)
pred_kn = kn.predict(features_test)
# print(pred_kn)

logleg = LogisticRegression(random_state=0)
logleg.fit(features_train, label_train)
pred_logleg = logleg.predict(features_test)
# print(pred_logleg)


# EVALUATION
print('confusion matrix  = \n', confusion_matrix(y_true=label_test, y_pred=pred_svc))
print('accurary =', svc.score(features_test, label_test))

print('confusion matrix  = \n', confusion_matrix(y_true=label_test, y_pred=pred_kn))
print('accurary =', kn.score(features_test, label_test))

print('confusion matrix  = \n', confusion_matrix(y_true=label_test, y_pred=pred_logleg))
print('accurary =', logleg.score(features_test, label_test))
```

### | å›å¸°äºˆæ¸¬

```python
import sklearn
import pandas as pd
from sklearn.datasets import load_boston
from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split

# ALGORITHM
from sklearn.linear_model import Lasso
from sklearn.linear_model import Ridge
from sklearn.linear_model import LinearRegression


# DATASET
boston = load_boston()
boston_features = pd.DataFrame(data=boston.data, columns=boston.feature_names)
boston_target = pd.Series(data=boston.target)


# EDA
# boston_features.head()
# boston_features.isnull().sum()
# boston_target.head()
# boston_target.describe()


X_train, X_test, y_train, y_test = train_test_split(boston_features, boston_target, test_size=0.5, random_state=0)

# MODEL
lasso = Lasso(alpha=0.1, random_state=0)
lasso.fit(X_train, y_train)
pred_lasso = lasso.predict(X_test)

ridge = Ridge(alpha=0.5, random_state=0)
ridge.fit(X_train, y_train)
pred_ridge = ridge.predict(X_test)

linreg = LinearRegression()
linreg.fit(X_train, y_train)
pred_linreg = linreg.predict(X_test)


# EVALUATION
print('R-squared : ', lasso.score(X_test, y_test).round(3))
print('R-squared : ', ridge.score(X_test, y_test).round(3))
print('R-squared : ', linreg.score(X_test, y_test).round(3))


cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)

model_list = ['lasso', 'ridge', 'linreg']

for i in model_list:
    score = cross_val_score(i, boston_features, boston_target, cv=cv)
    print(score)
    print('R-squared_Average : {0:.2f}'.format(score.mean()))
    print("-"*20)

```
Cf. [äº¤å·®æ¤œè¨¼ï¼ˆcross validationï¼ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰ã®ç¨®é¡ã‚’æ•´ç†ã—ã¦ã¿ãŸ](https://aizine.ai/cross-validation0910/) - AIZINE
